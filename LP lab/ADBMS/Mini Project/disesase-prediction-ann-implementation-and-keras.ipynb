{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Content\n* [Data Preprocessing](#1)\n    * [Import Libraries](#2)\n    * [Import Dataset](#3)\n    * [Encoding Categorical Data](#4)\n    * [Create test and train data (and x-y variables)](#5)\n    * [Feature Scaling](#6)\n* [Model Building](#7)\n    * [Implementing Basic Example ANN Structure with OOP](#8)\n    * [Fitting Model and Prediction](#9)\n    * [Building ANN Structure with Keras Library](#10)\n        * [Import Libraries](#11)\n        * [Initialize ANN Model](#12)\n        * [Adding the Layers](#13)\n        * [Compiling the ANN](#14)\n        * [Fitting the ANN](#15)\n        * [Making Prediction with Test Data](#16)\n        * [Accuracy Score and Loss Visualization](#17)\n    ","metadata":{}},{"cell_type":"markdown","source":"<a id = \"1\"></a>\n### Data Preprocessing\n<a id = \"2\"></a>\n#### Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-10-01T06:16:03.962577Z","iopub.execute_input":"2021-10-01T06:16:03.962955Z","iopub.status.idle":"2021-10-01T06:16:03.989004Z","shell.execute_reply.started":"2021-10-01T06:16:03.962862Z","shell.execute_reply":"2021-10-01T06:16:03.988068Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"3\"></a>\n#### Import Dataset","metadata":{}},{"cell_type":"code","source":"# It's already splitted as train and test data. So we had better import them train_data and test_data\n\ntrain_data = pd.read_csv(\"../input/disease-prediction-using-machine-learning/Training.csv\")\ntest_data = pd.read_csv(\"../input/disease-prediction-using-machine-learning/Testing.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-01T06:16:03.990489Z","iopub.execute_input":"2021-10-01T06:16:03.990720Z","iopub.status.idle":"2021-10-01T06:16:04.112717Z","shell.execute_reply.started":"2021-10-01T06:16:03.990696Z","shell.execute_reply":"2021-10-01T06:16:04.111999Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_data.columns.values.tolist()","metadata":{"execution":{"iopub.status.busy":"2021-10-01T06:16:32.545709Z","iopub.execute_input":"2021-10-01T06:16:32.546039Z","iopub.status.idle":"2021-10-01T06:16:32.558366Z","shell.execute_reply.started":"2021-10-01T06:16:32.546007Z","shell.execute_reply":"2021-10-01T06:16:32.557276Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:34.50373Z","iopub.execute_input":"2021-09-20T12:47:34.504041Z","iopub.status.idle":"2021-09-20T12:47:34.524213Z","shell.execute_reply.started":"2021-09-20T12:47:34.504001Z","shell.execute_reply":"2021-09-20T12:47:34.523515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info() ","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:34.525145Z","iopub.execute_input":"2021-09-20T12:47:34.52557Z","iopub.status.idle":"2021-09-20T12:47:34.543149Z","shell.execute_reply.started":"2021-09-20T12:47:34.52554Z","shell.execute_reply":"2021-09-20T12:47:34.542186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data has 134 columns. The 132 of the columns are symptoms, encoded integer data, and the \"prognosis\" column is categorical data for disease labels.","metadata":{}},{"cell_type":"code","source":"train_data.isnull().any()  #there is an unclean column named \"Unnamed: 133\". We will drop it","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:34.545302Z","iopub.execute_input":"2021-09-20T12:47:34.545651Z","iopub.status.idle":"2021-09-20T12:47:34.556299Z","shell.execute_reply.started":"2021-09-20T12:47:34.545614Z","shell.execute_reply":"2021-09-20T12:47:34.555418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we dont need Unnamed: 133 column to train\ntrain_data.drop([\"Unnamed: 133\"], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:34.557678Z","iopub.execute_input":"2021-09-20T12:47:34.557904Z","iopub.status.idle":"2021-09-20T12:47:34.566753Z","shell.execute_reply.started":"2021-09-20T12:47:34.55788Z","shell.execute_reply":"2021-09-20T12:47:34.56615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:34.567941Z","iopub.execute_input":"2021-09-20T12:47:34.568613Z","iopub.status.idle":"2021-09-20T12:47:34.595756Z","shell.execute_reply.started":"2021-09-20T12:47:34.568582Z","shell.execute_reply":"2021-09-20T12:47:34.594848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"4\"></a>\n#### Encoding Categorical Data","metadata":{}},{"cell_type":"markdown","source":"The data is already encoded but anyhow I will show how to encode categorical data.","metadata":{}},{"cell_type":"code","source":"# Label Encoding\n# from sklearn.preprocessing import LabelEncoder\n# labelencoder = LabelEncoder()\n\n# Lets assume we have categorical labels at first column (itching). If this column has True-False values or like Male-Female,\n# then it will tranform into 1-0 encoding. This is encoding. But as I say before, there is no need for encoding on this dataset\n\n# train_data.loc[:, 0] = labelencoder.fit_transform(train_data.iloc[:, 0])\n# train_data","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:34.596946Z","iopub.execute_input":"2021-09-20T12:47:34.597239Z","iopub.status.idle":"2021-09-20T12:47:34.601182Z","shell.execute_reply.started":"2021-09-20T12:47:34.597211Z","shell.execute_reply":"2021-09-20T12:47:34.600108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# One hot encoding\n# from sklearn.preprocessing import OneHotEncoder\n\n# Lets assume our second column (skin_rash) has more than two labels. This time, we will have to one hot encode the feature\n# First, we need to apply label encoding similarly as we did in the itching variable\n# After applying label encoding, now it's time to appy One Hot Encoding\n\n# onehotencoder = OneHotEncoder(categorical_features = [1])\n# labelencoder2 = LabelEncoder()\n# train_data.loc[:,1] = labelencoder2.fit_transform(train_data.iloc[:, 1])\n# train_data = onehotencoder.fit_transform(train_data).toarray()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:34.602227Z","iopub.execute_input":"2021-09-20T12:47:34.602419Z","iopub.status.idle":"2021-09-20T12:47:34.613208Z","shell.execute_reply.started":"2021-09-20T12:47:34.602396Z","shell.execute_reply":"2021-09-20T12:47:34.612256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"5\"></a>\n#### Create Test and Train Data","metadata":{}},{"cell_type":"code","source":"X_train = train_data.iloc[:, :-1]\nX_test = test_data.iloc[:, :-1]\ny_train = train_data.iloc[:, -1:]\ny_test = test_data.iloc[:, -1:]","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:34.614269Z","iopub.execute_input":"2021-09-20T12:47:34.615013Z","iopub.status.idle":"2021-09-20T12:47:34.634617Z","shell.execute_reply.started":"2021-09-20T12:47:34.614969Z","shell.execute_reply":"2021-09-20T12:47:34.633667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"X train shape: \",X_train.shape)\nprint(\"y train shape: \",y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:34.636952Z","iopub.execute_input":"2021-09-20T12:47:34.637302Z","iopub.status.idle":"2021-09-20T12:47:34.643692Z","shell.execute_reply.started":"2021-09-20T12:47:34.637268Z","shell.execute_reply":"2021-09-20T12:47:34.642413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Our x train data has 132 features and 4920 observation unit that means our input matrix has 4920 rows and 132 columns for training\n* Our y train data has one feature (itself) and 4920 observation unit that means our output matrix has 4920 rows and 1 column for training","metadata":{}},{"cell_type":"code","source":"print(\"X test shape: \",X_test.shape)\nprint(\"y test shape: \",y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:34.644762Z","iopub.execute_input":"2021-09-20T12:47:34.645791Z","iopub.status.idle":"2021-09-20T12:47:34.654239Z","shell.execute_reply.started":"2021-09-20T12:47:34.645751Z","shell.execute_reply":"2021-09-20T12:47:34.653553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Our x test data has 132 features and 42 observation unit that means our input matrix has 42 rows and 132 columns for prediction\n* Our y test data has one feature (itself) and 42 observation unit that means our output matrix has 42 rows and 1 column for prediction","metadata":{}},{"cell_type":"markdown","source":"<a id = \"6\"></a>\n#### Feature Scaling for Numerical Data","metadata":{}},{"cell_type":"markdown","source":"<img src= \"https://miro.medium.com/max/758/1*wuCX1bjSh6YXcu8tuA5wyw.png\" alt =\"Standardization and Normalization\">","metadata":{"execution":{"iopub.status.busy":"2021-09-18T09:09:19.361756Z","iopub.execute_input":"2021-09-18T09:09:19.362906Z","iopub.status.idle":"2021-09-18T09:09:19.372129Z","shell.execute_reply.started":"2021-09-18T09:09:19.362859Z","shell.execute_reply":"2021-09-18T09:09:19.370559Z"}}},{"cell_type":"code","source":"# Example of standardization and normalization\n\nx = np.array([1,23,5,564,56,876,7,-123])\n\nstandardized_X = (x - np.mean(x)) / np.std(x)\nnormalized_X = (x-np.min(x) / np.max(x) - np.min(x))\nprint(\"Standardized array: \",standardized_X)\nprint(\"Normalized array: \",normalized_X )","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:34.655061Z","iopub.execute_input":"2021-09-20T12:47:34.655436Z","iopub.status.idle":"2021-09-20T12:47:34.667948Z","shell.execute_reply.started":"2021-09-20T12:47:34.655405Z","shell.execute_reply":"2021-09-20T12:47:34.667142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# With sklearn scalers\nfrom sklearn.preprocessing import StandardScaler\nstds = StandardScaler()\nx = x.reshape(-1,1)  # for sklearn methods. they use two dimensional vectors\nx = stds.fit_transform(x)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:34.668969Z","iopub.execute_input":"2021-09-20T12:47:34.669606Z","iopub.status.idle":"2021-09-20T12:47:34.677144Z","shell.execute_reply.started":"2021-09-20T12:47:34.669573Z","shell.execute_reply":"2021-09-20T12:47:34.67652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"What if we apply standard scaling to our train symptoms data (X_train)?\n* This is a nonsensical situation because our symptoms are not numerical. They are categorical. So do not these bullshit =)","metadata":{}},{"cell_type":"markdown","source":"<a id = \"7\"></a>\n### Model Building\n<a id = \"8\"></a>\n#### Implementing Basic Example ANN Structure with OOP","metadata":{}},{"cell_type":"markdown","source":"Reference: https://www.geeksforgeeks.org/implementing-ann-training-process-in-python/","metadata":{}},{"cell_type":"markdown","source":"<img src= \"https://media.geeksforgeeks.org/wp-content/uploads/input_set.png\" alt =\"Basic ANN\">","metadata":{}},{"cell_type":"code","source":"class NeuralNet(object):\n    def __init__(self):\n        # Generate random numbers\n        np.random.seed(1)\n        \n        # Assign random weights to a 3 * 1 matrix\n        self.synaptic_weights = 2 * np.random.random((3, 1)) - 1\n        \n    # The sigmoid function method\n    def _sigmoid(self,x):\n        return 1 / (1 + np.exp(-x))\n    \n    # Derivative sigmoid\n    def derivative_sigmoid(self, x):\n        return x * (1 - x)\n    \n    # Train the neural network and adjust the weights each time\n    def train(self, inputs, outputs, iteration_number):\n        for iteration in range(iteration_number):     \n        \n            # Pass the training set through network\n            output = self.learn(inputs)\n        \n            # Calculate the error\n            error = outputs - output\n        \n            # Adjust the weights by a factor\n            factor = np.dot(inputs.T, error * self.derivative_sigmoid(output))\n            self.synaptic_weights += factor\n        \n    # calculate z    \n    def learn(self, test_inputs):\n        return self._sigmoid(np.dot(test_inputs, self.synaptic_weights))","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:34.678084Z","iopub.execute_input":"2021-09-20T12:47:34.678685Z","iopub.status.idle":"2021-09-20T12:47:34.688524Z","shell.execute_reply.started":"2021-09-20T12:47:34.678646Z","shell.execute_reply":"2021-09-20T12:47:34.687875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"9\"></a>\n#### Fitting Model and Prediction","metadata":{}},{"cell_type":"code","source":"# Initialize\nneural_net = NeuralNet()\n\n# The training set\ninputs = np.array([[0, 1, 1], [1, 0, 0], [1, 0, 1]])\noutputs = np.array([[1, 0, 1]]).T\n\n# train the neural network\nneural_net.train(inputs, outputs, 50)\n\ntest_inputs = np.array([1, 0, 1])\nthreshold = 0.5\nif neural_net.learn(test_inputs) >= threshold:\n    print(\"Our test example output is: 1\")\nelse:\n    print(\"Our test example output is: 0\")","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:34.689618Z","iopub.execute_input":"2021-09-20T12:47:34.690016Z","iopub.status.idle":"2021-09-20T12:47:34.706098Z","shell.execute_reply.started":"2021-09-20T12:47:34.689931Z","shell.execute_reply":"2021-09-20T12:47:34.704873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform into dummies for y_train (prognosis variable)\ny_train_dum = pd.get_dummies(y_train)\ny_train_dum","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:34.707331Z","iopub.execute_input":"2021-09-20T12:47:34.707669Z","iopub.status.idle":"2021-09-20T12:47:34.7335Z","shell.execute_reply.started":"2021-09-20T12:47:34.707642Z","shell.execute_reply":"2021-09-20T12:47:34.732539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"10\"></a>\n### Building ANN Structure with Keras Library\n<a id = \"11\"></a>\n#### Import Libraries","metadata":{}},{"cell_type":"code","source":"# import tensorflow and keras\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential   # used for initialize ANN model\nfrom tensorflow.keras import layers   # used for different layer structure\nfrom tensorflow.keras.layers import Dense","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:34.734628Z","iopub.execute_input":"2021-09-20T12:47:34.734839Z","iopub.status.idle":"2021-09-20T12:47:34.739889Z","shell.execute_reply.started":"2021-09-20T12:47:34.734815Z","shell.execute_reply":"2021-09-20T12:47:34.739133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"12\"></a>\n#### Initialize the ANN Model","metadata":{}},{"cell_type":"code","source":"classifier = Sequential()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:34.740858Z","iopub.execute_input":"2021-09-20T12:47:34.741086Z","iopub.status.idle":"2021-09-20T12:47:34.753819Z","shell.execute_reply.started":"2021-09-20T12:47:34.74105Z","shell.execute_reply":"2021-09-20T12:47:34.752688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"13\"></a>\n#### Adding the Layers","metadata":{}},{"cell_type":"code","source":"# adding first hidden layer with input layer. there is init parameter that represents how to initialize weights\nclassifier.add(Dense(64, activation = \"relu\", input_dim = X_train.shape[1]))\n# adding second hidden layer\nclassifier.add(Dense(32, activation = \"relu\"))\n# adding last layer\nclassifier.add(Dense(y_train_dum.shape[1], activation = \"softmax\"))","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:34.75556Z","iopub.execute_input":"2021-09-20T12:47:34.755971Z","iopub.status.idle":"2021-09-20T12:47:34.787159Z","shell.execute_reply.started":"2021-09-20T12:47:34.755927Z","shell.execute_reply":"2021-09-20T12:47:34.786267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"14\"></a>\n#### Compiling the ANN Model","metadata":{}},{"cell_type":"code","source":"classifier.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\nclassifier.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:34.788471Z","iopub.execute_input":"2021-09-20T12:47:34.788672Z","iopub.status.idle":"2021-09-20T12:47:34.802694Z","shell.execute_reply.started":"2021-09-20T12:47:34.788649Z","shell.execute_reply":"2021-09-20T12:47:34.801815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"15\"></a>\n#### Fitting the ANN","metadata":{}},{"cell_type":"code","source":"history = classifier.fit(X_train, y_train_dum, epochs = 5, batch_size = 30)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:34.804147Z","iopub.execute_input":"2021-09-20T12:47:34.804771Z","iopub.status.idle":"2021-09-20T12:47:36.079982Z","shell.execute_reply.started":"2021-09-20T12:47:34.804729Z","shell.execute_reply":"2021-09-20T12:47:36.07898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"16\"></a>\n#### Making Prediction","metadata":{}},{"cell_type":"code","source":"prediction = classifier.predict_classes(X_test)\nprediction","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:36.081875Z","iopub.execute_input":"2021-09-20T12:47:36.082208Z","iopub.status.idle":"2021-09-20T12:47:36.168389Z","shell.execute_reply.started":"2021-09-20T12:47:36.082169Z","shell.execute_reply":"2021-09-20T12:47:36.167485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"17\"></a>\n#### Accuracy and Loss Visualization","metadata":{}},{"cell_type":"code","source":"history.history[\"accuracy\"]","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:36.169811Z","iopub.execute_input":"2021-09-20T12:47:36.170458Z","iopub.status.idle":"2021-09-20T12:47:36.175705Z","shell.execute_reply.started":"2021-09-20T12:47:36.170427Z","shell.execute_reply":"2021-09-20T12:47:36.174851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history[\"accuracy\"])\nplt.title(\"Model accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy score\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:47:36.176935Z","iopub.execute_input":"2021-09-20T12:47:36.177284Z","iopub.status.idle":"2021-09-20T12:47:36.383788Z","shell.execute_reply.started":"2021-09-20T12:47:36.177249Z","shell.execute_reply":"2021-09-20T12:47:36.382917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history[\"loss\"])\nplt.title(\"Model loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T12:48:09.480493Z","iopub.execute_input":"2021-09-20T12:48:09.480805Z","iopub.status.idle":"2021-09-20T12:48:09.665148Z","shell.execute_reply.started":"2021-09-20T12:48:09.480764Z","shell.execute_reply":"2021-09-20T12:48:09.664372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}